from flask import Flask, request, jsonify
import base64
from PIL import Image
from io import BytesIO
import os
import torch
from datetime import datetime
from transformers import AutoTokenizer, AutoModelForCausalLM, AutoProcessor
print("ğŸš€ é–‹å§‹åŸ·è¡Œ app.py")

local_model_path = "./models/Ovis2-4B"

model = AutoModelForCausalLM.from_pretrained(
    local_model_path,
    torch_dtype=torch.float16,
    trust_remote_code=True,
).to("cpu")
tokenizer = AutoTokenizer.from_pretrained(local_model_path, trust_remote_code=True)
processor = AutoProcessor.from_pretrained(local_model_path, trust_remote_code=True)
print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
app = Flask(__name__)

SAVE_DIR = "captured_images"
os.makedirs(SAVE_DIR, exist_ok=True)

@app.route('/ovis-recognize', methods=['POST'])
def recognize():
    try:
        data = request.get_json()
        image_b64 = data.get('image')

        if not image_b64.startswith('data:image'):
            return jsonify({'error': 'ç„¡æ•ˆåœ–ç‰‡æ ¼å¼'}), 400

        header, encoded = image_b64.split(',', 1)
        image_bytes = base64.b64decode(encoded)
        image = Image.open(BytesIO(image_bytes)).convert('RGB')

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        image_path = os.path.join(SAVE_DIR, f"captured_image_{timestamp}.jpg")
        image.save(image_path)  
        print(f"ğŸ“· åœ–ç‰‡å·²å„²å­˜ï¼š{image_path}")

        prompt = "<|image|> è«‹è¾¨è­˜åœ–ä¸­ç‰©é«”çš„é¡å‹ã€å¯¬ã€é«˜ã€æ·±ã€é¡è‰²ã€æ˜¯å¦ç°ç©ºèˆ‡æ´å°ºå¯¸ã€‚"
        inputs = processor(image, prompt, return_tensors="pt").to("cuda")
        with torch.inference_mode():
            generated_ids = model.generate(**inputs, max_new_tokens=128)
        output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
        print("[æ¨¡å‹è¾¨è­˜çµæœ]", output)
        return jsonify({"text": output})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    print("âœ… å•Ÿå‹• Flask...")
    app.run(host="localhost", port=5000)
